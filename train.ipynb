{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297c8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Retrival_Dino_Salad.model import SaladFaissGPSDB\n",
    "from preprocess import CampusGPSDataset\n",
    "import torchvision.transforms.v2 as v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648ec93",
   "metadata": {},
   "source": [
    "# Extract Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403012d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split \n",
    "transform = v2.Compose([\n",
    "    v2.Resize((4004, 3010), interpolation=v2.InterpolationMode.BILINEAR),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = CampusGPSDataset(csv_path=\"data\\photo_locations.csv\", image_dir=\"data\\indexed_photos\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645410f",
   "metadata": {},
   "source": [
    "# Train Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9a2ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\PC/.cache\\torch\\hub\\serizba_salad_main\n",
      "Using cache found in C:\\Users\\PC/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "0it [00:33, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.92 GiB is allocated by PyTorch, and 116.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m db \u001b[38;5;241m=\u001b[39m SaladFaissGPSDB(model, use_cosine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 2) Build database from train loader (must yield images + gps tensor [B,2])\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_from_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 3) Save index + gps/meta\u001b[39;00m\n\u001b[0;32m      8\u001b[0m db\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalad_faiss_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\Works\\semester g\\Deep\\Image2GPS-Deep\\Retrival_Dino_Salad\\model.py:147\u001b[0m, in \u001b[0;36mSaladFaissGPSDB.build_from_loader\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected gps_tensor shape [B,2], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(gps_tensor\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m gps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m gps_tensor\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m--> 147\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# returns np.ndarray [B,D]\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embeddings(embs, gps)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\Image2GPS\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Desktop\\Works\\semester g\\Deep\\Image2GPS-Deep\\Retrival_Dino_Salad\\model.py:81\u001b[0m, in \u001b[0;36mSaladFaissGPSDB.embed\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages must be [B,3,H,W], got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images)\n\u001b[0;32m     84\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_extractor(model_out)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.92 GiB is allocated by PyTorch, and 116.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 1) Load model\n",
    "model = torch.hub.load(\"serizba/salad\", \"dinov2_salad\")\n",
    "db = SaladFaissGPSDB(model, use_cosine=True, normalize=True)\n",
    "# 2) Build database from train loader (must yield images + gps tensor [B,2])\n",
    "db.build_from_loader(train_loader)\n",
    "\n",
    "# 3) Save index + gps/meta\n",
    "db.save(\"salad_faiss_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a7fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_gpez: [31.262210845947266, 34.80329513549805]\n",
      "pred_gpez: 31.262016615941867 34.80351222407907\n"
     ]
    }
   ],
   "source": [
    "# 4) Load later\n",
    "db2 = SaladFaissGPSDB.load(\"salad_faiss_db\", model=model)\n",
    "\n",
    "# 5) Predict GPS for a new image tensor [3,H,W]\n",
    "query_img, query_gps = val_dataset[0]  # just an example\n",
    "pred_lat, pred_lon = db2.predict_gps(query_img, k=5, weighted=True)\n",
    "\n",
    "# # 6) Or inspect top matches (for debugging)\n",
    "# matches = db2.query_image(query_img, k=5)\n",
    "# for m in matches:\n",
    "#     print(m.idx, m.score, m.gps)\n",
    "\n",
    "print(\"real_gpez:\", query_gps.tolist())\n",
    "print(\"pred_gpez:\", pred_lat, pred_lon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image2GPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
